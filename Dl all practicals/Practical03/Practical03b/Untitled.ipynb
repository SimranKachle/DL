{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4414296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,Flatten,MaxPooling2D\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1740fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labes=['T-shirts/Top','Trousers','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d684e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()\n",
    "\n",
    "train_images=train_images.reshape((train_images.shape[0],28,28,1)).astype('float32')/255\n",
    "test_images=test_images.reshape((test_images.shape[0],28,28,1)).astype('float32')/255\n",
    "\n",
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522def3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "  Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "   MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64,(3,3),activation='relu'),\n",
    "   MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64,(3,3),activation='relu'),\n",
    "   Flatten(),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40cf2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba96cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "750/750 [==============================] - 41s 52ms/step - loss: 0.5684 - accuracy: 0.7924 - val_loss: 0.3887 - val_accuracy: 0.8595\n",
      "Epoch 2/15\n",
      "750/750 [==============================] - 37s 50ms/step - loss: 0.3600 - accuracy: 0.8712 - val_loss: 0.3315 - val_accuracy: 0.8790\n",
      "Epoch 3/15\n",
      "750/750 [==============================] - 37s 49ms/step - loss: 0.3060 - accuracy: 0.8899 - val_loss: 0.3153 - val_accuracy: 0.8855\n",
      "Epoch 4/15\n",
      "750/750 [==============================] - 39s 51ms/step - loss: 0.2739 - accuracy: 0.9004 - val_loss: 0.2883 - val_accuracy: 0.8940\n",
      "Epoch 5/15\n",
      "750/750 [==============================] - 39s 52ms/step - loss: 0.2467 - accuracy: 0.9101 - val_loss: 0.2752 - val_accuracy: 0.8984\n",
      "Epoch 6/15\n",
      "750/750 [==============================] - 39s 52ms/step - loss: 0.2281 - accuracy: 0.9167 - val_loss: 0.2690 - val_accuracy: 0.9025\n",
      "Epoch 7/15\n",
      "750/750 [==============================] - 39s 53ms/step - loss: 0.2084 - accuracy: 0.9234 - val_loss: 0.2837 - val_accuracy: 0.8970\n",
      "Epoch 8/15\n",
      "750/750 [==============================] - 44s 59ms/step - loss: 0.1930 - accuracy: 0.9280 - val_loss: 0.2561 - val_accuracy: 0.9085\n",
      "Epoch 9/15\n",
      "750/750 [==============================] - 49s 66ms/step - loss: 0.1778 - accuracy: 0.9345 - val_loss: 0.2590 - val_accuracy: 0.9103\n",
      "Epoch 10/15\n",
      "750/750 [==============================] - 43s 57ms/step - loss: 0.1622 - accuracy: 0.9409 - val_loss: 0.2617 - val_accuracy: 0.9058\n",
      "Epoch 11/15\n",
      "750/750 [==============================] - 42s 57ms/step - loss: 0.1499 - accuracy: 0.9448 - val_loss: 0.2692 - val_accuracy: 0.9088\n",
      "Epoch 12/15\n",
      "750/750 [==============================] - 44s 59ms/step - loss: 0.1354 - accuracy: 0.9497 - val_loss: 0.2702 - val_accuracy: 0.9092\n",
      "Epoch 13/15\n",
      "750/750 [==============================] - 46s 62ms/step - loss: 0.1231 - accuracy: 0.9534 - val_loss: 0.2879 - val_accuracy: 0.9072\n",
      "Epoch 14/15\n",
      "750/750 [==============================] - 46s 61ms/step - loss: 0.1142 - accuracy: 0.9576 - val_loss: 0.2905 - val_accuracy: 0.9089\n",
      "Epoch 15/15\n",
      "750/750 [==============================] - 46s 62ms/step - loss: 0.1022 - accuracy: 0.9624 - val_loss: 0.3081 - val_accuracy: 0.9116\n",
      "Training time is:  -632.9222767353058\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "model.fit(train_images,train_labels,epochs=15,batch_size=64,validation_split=0.2)\n",
    "train_time = start - time.time()\n",
    "print(\"Training time is: \", train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82ae4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_predict_image(image_path):\n",
    "    # Read and preprocess the image\n",
    "    img = preprocess_image(image_path)\n",
    "    # Predict the class and measure prediction time\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(img)\n",
    "    pred_time = time.time() - start_time\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predicted_class = class_labes[predicted_class_index]  # Get the class name from class_labels\n",
    "    return predicted_class, pred_time\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image from the file path\n",
    "    img = load_img(image_path, target_size=(28, 28), color_mode=\"grayscale\")\n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = img_to_array(img)\n",
    "    # Invert the grayscale values (black -> white, white -> black)\n",
    "    img_array = 255 - img_array\n",
    "    # Reshape the image array to add a dimension for the color channel (even though it's grayscale)\n",
    "    img_array = img_array.reshape((1, 28, 28, 1))\n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "    return img_array / 255.0\n",
    "\n",
    "\n",
    "def browse_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        predicted_class, pred_time = preprocess_and_predict_image(file_path)\n",
    "        result_label.config(text=f\"Predicted Class: {predicted_class}\\nPrediction Time: {pred_time:.4f} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26328770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create a Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Fashion MNIST Image Classifier\")\n",
    "\n",
    "# Create a button to browse the image\n",
    "browse_button = tk.Button(root, text=\"Browse Image\", command=browse_image)\n",
    "browse_button.pack(pady=10)\n",
    "\n",
    "# Label to display the predicted class\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.pack(pady=5)\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9a7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
